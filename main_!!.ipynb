{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Prediction using Spectrograms and Vision Transformers\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This repository implements a pipeline to predict stock price movements using spectrograms generated from financial time-series data. The model uses Vision Transformers (ViTs) trained on spectrograms to capture temporal and frequency patterns in stock prices.\n",
    "\n",
    "---\n",
    "\n",
    "## Project Steps\n",
    "\n",
    "### 1. **Data Acquisition**\n",
    "- Download daily adjusted close prices for S&P 500 stocks from Yahoo Finance.\n",
    "- Timeframe: From 2000 to the most recent date.\n",
    "\n",
    "### **Training and Testing Split**\n",
    "\n",
    "\t•\tTraining Data:\n",
    "\t•\tData from 2000 to 2014 was used for training.\n",
    "\t•\tA total of 46,875 time series segments were sampled for training, with an 80-20 split between training and validation.\n",
    "\t•\tTest Data:\n",
    "\t•\tData from 2016 to 2019 was used for testing.\n",
    "\t•\tA total of 15,625 time series segments were sampled for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  5 of 5 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Scarica dati storici per una lista di tickers\n",
    "def download_sp500_data(tickers, start_date, end_date):\n",
    "    data = yf.download(tickers, start=start_date, end=end_date, group_by='ticker', auto_adjust=True)\n",
    "    return {ticker: data[ticker]['Close'].dropna() for ticker in tickers}\n",
    "\n",
    "# Parametri\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']  # Sostituisci con una lista più ampia\n",
    "start_date = \"2000-01-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "# Scarica i dati\n",
    "sp500_data = download_sp500_data(tickers, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero totale di segmenti generati: 510\n"
     ]
    }
   ],
   "source": [
    "# Crea segmenti di lunghezza fissa\n",
    "def create_segments(data, window_size=100, overlap=0.5):\n",
    "    step = int(window_size * (1 - overlap))  # Calcola passo in base all'overlap\n",
    "    segments = []\n",
    "    for ticker, series in data.items():\n",
    "        series = series.to_numpy()\n",
    "        for i in range(0, len(series) - window_size + 1, step):\n",
    "            segment = series[i:i + window_size]\n",
    "            segments.append({'ticker': ticker, 'segment': segment})\n",
    "    return segments\n",
    "\n",
    "# Genera segmenti (50% overlap per aumentare i campioni)\n",
    "segments = create_segments(sp500_data, window_size=100, overlap=0.5)\n",
    "print(f\"Numero totale di segmenti generati: {len(segments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages/pywt/_cwt.py:117: FutureWarning: Wavelets from the family cmor, without parameters specified in the name are deprecated. The name should follow the format cmorB-C, where B and C are floats representing the bandwidth frequency and center frequency, respectively (example, for backward compatibility: cmor = cmor1.0-0.5).\n",
      "  wavelet = DiscreteContinuousWavelet(wavelet)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Crea directory per salvare le immagini\n",
    "output_dir = \"/Users/roberto/Desktop/UNI_DATASCIENCE/FDS/FDS_final/spectrograms\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Genera spettrogrammi per i segmenti\n",
    "def generate_and_save_spectrograms(segments, wavelet='cmor', scale_range=(1, 64)):\n",
    "    for idx, segment_data in enumerate(segments):\n",
    "        ticker = segment_data['ticker']\n",
    "        segment = segment_data['segment']\n",
    "\n",
    "        # Genera Continuous Wavelet Transform (CWT)\n",
    "        scales = np.arange(scale_range[0], scale_range[1])\n",
    "        coefficients, frequencies = pywt.cwt(segment, scales, wavelet)\n",
    "\n",
    "        # Salva lo spettrogramma\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(\n",
    "            np.abs(coefficients), \n",
    "            extent=[0, len(segment), scale_range[0], scale_range[1]], \n",
    "            cmap='jet', \n",
    "            aspect='auto', \n",
    "            origin='lower'\n",
    "        )\n",
    "        plt.colorbar(label='Magnitudo')\n",
    "        plt.title(f\"Spettrogramma - {ticker} - Segment {idx}\")\n",
    "        plt.xlabel(\"Tempo\")\n",
    "        plt.ylabel(\"Scala\")\n",
    "        \n",
    "        # Salva l'immagine\n",
    "        filename = f\"{output_dir}/{ticker}_segment_{idx}.png\"\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "\n",
    "# Genera spettrogrammi\n",
    "generate_and_save_spectrograms(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define directories\n",
    "base_dir = \"/Users/roberto/Desktop/UNI_DATASCIENCE/FDS/FDS_final/spectrograms\"\n",
    "output_dir = \"data\"\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Define categories\n",
    "categories = [\"positive\", \"negative\"]  # Adjust as needed\n",
    "\n",
    "# Create output directories\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for category in categories:\n",
    "        os.makedirs(os.path.join(output_dir, split, category), exist_ok=True)\n",
    "\n",
    "# Split images\n",
    "def split_data(base_dir, output_dir, categories, train_ratio, val_ratio):\n",
    "    for category in categories:\n",
    "        images = os.listdir(os.path.join(base_dir, category))\n",
    "        random.shuffle(images)\n",
    "        \n",
    "        train_split = int(len(images) * train_ratio)\n",
    "        val_split = int(len(images) * (train_ratio + val_ratio))\n",
    "\n",
    "        for idx, image in enumerate(images):\n",
    "            if idx < train_split:\n",
    "                split = \"train\"\n",
    "            elif idx < val_split:\n",
    "                split = \"val\"\n",
    "            else:\n",
    "                split = \"test\"\n",
    "            \n",
    "            src = os.path.join(base_dir, category, image)\n",
    "            dst = os.path.join(output_dir, split, category, image)\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "split_data(base_dir, output_dir, categories, train_ratio, val_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anoter Test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and segment data\n",
    "def preprocess_and_segment(data, window_size=100):\n",
    "    segments = []\n",
    "    for ticker, series in data.items():\n",
    "        series = series.fillna(method=\"ffill\")  # Fill missing values\n",
    "        scaled_series = (series - series.min()) / (series.max() - series.min())  # Normalize\n",
    "        for i in range(0, len(scaled_series) - window_size + 1, window_size):\n",
    "            segment = scaled_series.iloc[i:i + window_size]\n",
    "            segments.append({\"ticker\": ticker, \"segment\": segment})\n",
    "    return segments\n",
    "\n",
    "# Create 100-day segments\n",
    "segments = preprocess_and_segment(data, window_size=100)\n",
    "print(f\"Generated {len(segments)} segments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  5 of 5 completed\n",
      "[*********************100%***********************]  5 of 5 completed\n",
      "/var/folders/jp/fnr369_172b9ghtllhyqdmtw0000gp/T/ipykernel_16332/2826110225.py:26: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  series = series.fillna(method='ffill')\n",
      "/Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages/pywt/_cwt.py:117: FutureWarning: Wavelets from the family cmor, without parameters specified in the name are deprecated. The name should follow the format cmorB-C, where B and C are floats representing the bandwidth frequency and center frequency, respectively (example, for backward compatibility: cmor = cmor1.0-0.5).\n",
      "  wavelet = DiscreteContinuousWavelet(wavelet)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 125 segments\n",
      "Validation Set: 32 segments\n",
      "Test Set: 50 segments\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Data Acquisition ---\n",
    "def download_data(tickers, start_date, end_date):\n",
    "    \"\"\"\"\"\n",
    "    Download adjusted close prices for a list of tickers from Yahoo Finance.\n",
    "    \"\"\"\n",
    "    data = yf.download(tickers, start=start_date, end=end_date, group_by='ticker', auto_adjust=True)\n",
    "    return {ticker: data[ticker]['Close'].dropna() for ticker in tickers}\n",
    "\n",
    "# Example tickers (use S&P 500 for actual implementation)\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']\n",
    "train_start, train_end = \"2000-01-01\", \"2015-12-31\"\n",
    "test_start, test_end = \"2016-01-01\", \"2019-12-31\"\n",
    "\n",
    "# Download training and test data\n",
    "train_data = download_data(tickers, train_start, train_end)\n",
    "test_data = download_data(tickers, test_start, test_end)\n",
    "\n",
    "# --- 2. Data Preprocessing ---\n",
    "def preprocess_data(data, window_size=100):\n",
    "    \"\"\"\n",
    "    Preprocess data by normalizing and splitting into 100-day segments.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    for ticker, series in data.items():\n",
    "        # Forward fill missing values and normalize\n",
    "        series = series.fillna(method='ffill')\n",
    "        scaled_series = (series - series.min()) / (series.max() - series.min())\n",
    "        \n",
    "        # Create 100-day non-overlapping segments\n",
    "        for i in range(0, len(scaled_series) - window_size + 1, window_size):\n",
    "            segment = scaled_series.iloc[i:i + window_size]\n",
    "            segments.append({'ticker': ticker, 'segment': segment})\n",
    "    return segments\n",
    "\n",
    "# Preprocess data\n",
    "train_segments = preprocess_data(train_data)\n",
    "test_segments = preprocess_data(test_data)\n",
    "\n",
    "# --- 3. Spectrogram Generation ---\n",
    "def generate_spectrogram(segment, output_dir, idx, wavelet='cmor'):\n",
    "    \"\"\"\n",
    "    Generate a time-frequency spectrogram from a segment using wavelet transform.\n",
    "    \"\"\"\n",
    "    data = segment.to_numpy()\n",
    "    scales = np.arange(1, 64)  # Define wavelet scales\n",
    "    coefficients, _ = pywt.cwt(data, scales, wavelet)\n",
    "    \n",
    "    # Create spectrogram augmented with time-series intensity stripe\n",
    "    intensity_row = np.tile(data, (16, 1))  # Repeat the time series as a 2D row\n",
    "    spectrogram = np.vstack([intensity_row, np.abs(coefficients)])  # Combine intensity and spectrogram\n",
    "\n",
    "    # Save spectrogram as an image\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.imshow(spectrogram, extent=[0, len(data), 1, 64], cmap='jet', aspect='auto', origin='lower')\n",
    "    plt.colorbar(label='Magnitude')\n",
    "    plt.title(f\"Spectrogram - Segment {idx}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Scale\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(f\"{output_dir}/segment_{idx}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Generate spectrograms for training data\n",
    "output_dir = \"train_spectrograms\"\n",
    "for idx, seg in enumerate(train_segments):\n",
    "    generate_spectrogram(seg['segment'], output_dir, idx)\n",
    "\n",
    "# Generate spectrograms for test data\n",
    "output_dir = \"test_spectrograms\"\n",
    "for idx, seg in enumerate(test_segments):\n",
    "    generate_spectrogram(seg['segment'], output_dir, idx)\n",
    "\n",
    "# --- 4. Prepare for Training/Test Split ---\n",
    "def split_train_val(data, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Split data into training and validation sets.\n",
    "    \"\"\"\n",
    "    np.random.shuffle(data)\n",
    "    split_idx = int(len(data) * train_ratio)\n",
    "    return data[:split_idx], data[split_idx:]\n",
    "\n",
    "# Split into train/val for training data\n",
    "train_set, val_set = split_train_val(train_segments)\n",
    "\n",
    "# --- Summary of Dataset ---\n",
    "print(f\"Training Set: {len(train_set)} segments\")\n",
    "print(f\"Validation Set: {len(val_set)} segments\")\n",
    "print(f\"Test Set: {len(test_segments)} segments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total S&P 500 tickers: 503\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fetch S&P 500 tickers from Wikipedia\n",
    "def get_sp500_tickers():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    table = pd.read_html(url, header=0)[0]\n",
    "    return table['Symbol'].tolist()\n",
    "\n",
    "tickers = get_sp500_tickers()\n",
    "print(f\"Total S&P 500 tickers: {len(tickers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training segments: 310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jp/fnr369_172b9ghtllhyqdmtw0000gp/T/ipykernel_16332/4156595069.py:10: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  series = series.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Adjust the segment creation to include overlap\n",
    "def preprocess_data_with_overlap(data, window_size=100, overlap=0.5):\n",
    "    \"\"\"\n",
    "    Preprocess data by normalizing and splitting into overlapping 100-day segments.\n",
    "    \"\"\"\n",
    "    step = int(window_size * (1 - overlap))  # Calculate step size based on overlap\n",
    "    segments = []\n",
    "    for ticker, series in data.items():\n",
    "        # Forward fill missing values and normalize\n",
    "        series = series.fillna(method='ffill')\n",
    "        scaled_series = (series - series.min()) / (series.max() - series.min())\n",
    "        \n",
    "        # Create overlapping segments\n",
    "        for i in range(0, len(scaled_series) - window_size + 1, step):\n",
    "            segment = scaled_series.iloc[i:i + window_size]\n",
    "            segments.append({'ticker': ticker, 'segment': segment})\n",
    "    return segments\n",
    "\n",
    "# Example with 50% overlap\n",
    "train_segments = preprocess_data_with_overlap(train_data, window_size=100, overlap=0.5)\n",
    "print(f\"Number of training segments: {len(train_segments)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.1-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.68.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/roberto/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-macosx_12_0_arm64.whl (239.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.68.1-cp311-cp311-macosx_10_9_universal2.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp311-cp311-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-macosx_10_9_universal2.whl (397 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.1-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp311-cp311-macosx_11_0_arm64.whl (318 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 h5py-3.12.1 keras-3.7.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 protobuf-5.29.1 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 werkzeug-3.1.3 wheel-0.45.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL: Start - 2000-01-03 00:00:00, End - 2015-12-30 00:00:00\n",
      "MSFT: Start - 2000-01-03 00:00:00, End - 2015-12-30 00:00:00\n",
      "GOOGL: Start - 2004-08-19 00:00:00, End - 2015-12-30 00:00:00\n",
      "AMZN: Start - 2000-01-03 00:00:00, End - 2015-12-30 00:00:00\n",
      "META: Start - 2012-05-18 00:00:00, End - 2015-12-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Check date range coverage for each stock\n",
    "for ticker, series in train_data.items():\n",
    "    print(f\"{ticker}: Start - {series.index.min()}, End - {series.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[1;32m      3\u001b[0m     rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      4\u001b[0m     width_shift_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m      5\u001b[0m     height_shift_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m      6\u001b[0m     horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Augment images in batches during training\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:1138\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1122\u001b[0m     directory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1137\u001b[0m ):\n\u001b[0;32m-> 1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:453\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m    452\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    455\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example of data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Augment images in batches during training\n",
    "train_data = datagen.flow_from_directory(\n",
    "    \"data/train\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
