{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jp/fnr369_172b9ghtllhyqdmtw0000gp/T/ipykernel_18057/1412126514.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mannual_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf'Day_{i+1}'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannual_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mannual_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Creazione delle tabelle annuali per i prezzi di chiusura\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mjnj_close_annual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_annual_close_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adbe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0madbe_close_annual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_annual_close_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madbe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jnj'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Esporta le tabelle annuali in formato CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jp/fnr369_172b9ghtllhyqdmtw0000gp/T/ipykernel_18057/1412126514.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(data, asset_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mannual_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myears\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0myearly_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mclose_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myearly_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mannual_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclose_prices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mannual_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannual_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "start_date = '2013-01-01'\n",
    "end_date = '2023-01-01'\n",
    "\n",
    "\n",
    "# Scarica i dati per jonson and jonson:\n",
    "jnj = yf.download('jnj', start=start_date, end=end_date)\n",
    "\n",
    "# Scarica i dati per adobe :\n",
    "adbe = yf.download('adbe', start=start_date, end=end_date)\n",
    "\n",
    "# Funzione per creare tabelle annuali con prezzi di chiusura\n",
    "def create_annual_close_table(data, asset_name):\n",
    "    # Rimuovi le osservazioni con valori nulli o NaN\n",
    "    data = data.dropna()\n",
    "    years = data.index.year.unique()\n",
    "    annual_data = []\n",
    "\n",
    "    for year in years:\n",
    "        yearly_data = data[data.index.year == year]\n",
    "        close_prices = yearly_data['Close'].tolist()\n",
    "        annual_data.append([year] + close_prices)\n",
    "\n",
    "    annual_df = pd.DataFrame(annual_data)\n",
    "    annual_df.columns = ['Year'] + [f'Day_{i+1}' for i in range(len(annual_df.columns) - 1)]\n",
    "    return annual_df\n",
    "\n",
    "# Creazione delle tabelle annuali per i prezzi di chiusura\n",
    "jnj_close_annual = create_annual_close_table(jnj, 'adbe')\n",
    "adbe_close_annual = create_annual_close_table(adbe, 'jnj')\n",
    "\n",
    "# Esporta le tabelle annuali in formato CSV\n",
    "jnj_close_annual.to_csv('/Users/roberto/Desktop/UNI 3^ ANNO/tesi/dataset/data_jnj.csv', index=False)\n",
    "adbe_close_annual.to_csv('/Users/roberto/Desktop/UNI 3^ ANNO/tesi/dataset/data_adbe.csv', index=False)\n",
    "\n",
    "print(\"Tabelle annuali dei prezzi di chiusura create e salvate in file CSV separati con successo!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le ultime due colonne sono state eliminate con successo.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carica il dataset dal file CSV\n",
    "csv_file = '/Users/roberto/Desktop/UNI 3^ ANNO/tesi/dataset/data_jnj.csv'  # Inserisci il percorso del tuo file CSV\n",
    "dati = pd.read_csv(csv_file)\n",
    "\n",
    "# Elimina le ultime due colonne\n",
    "dati_senza_ultime_due = dati.iloc[:, :-2]\n",
    "\n",
    "# Salva il dataset modificato in un nuovo file CSV\n",
    "dati_senza_ultime_due.to_csv('/Users/roberto/Desktop/UNI 3^ ANNO/tesi/dataset/adbe.csv', index=False)\n",
    "\n",
    "print(\"Le ultime due colonne sono state eliminate con successo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cella 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=81'>82</a>\u001b[0m csv_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/roberto/Desktop/UNI 3^ ANNO/tesi/dataset/adbe.csv\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Percorso del file CSV con i dati\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=82'>83</a>\u001b[0m output_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectograms_adbe\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Cartella di output per salvare gli spettrogrammi\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=83'>84</a>\u001b[0m genera_spettrogrammi_per_tutti_gli_anni(csv_file, output_dir)\n",
      "\u001b[1;32mUntitled-1.ipynb Cella 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=63'>64</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=64'>65</a>\u001b[0m \u001b[39mGenera spettrogrammi per ogni anno nel file CSV e li salva nella cartella di output.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=65'>66</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=66'>67</a>\u001b[0m \u001b[39m# Carica i dati dal file CSV\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=67'>68</a>\u001b[0m dati \u001b[39m=\u001b[39m carica_dati(csv_file)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=69'>70</a>\u001b[0m \u001b[39m# Crea la cartella di output se non esiste\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=70'>71</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(output_dir):\n",
      "\u001b[1;32mUntitled-1.ipynb Cella 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=7'>8</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=8'>9</a>\u001b[0m \u001b[39mCarica i dati di serie storiche da un file CSV.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=9'>10</a>\u001b[0m \u001b[39mSupponiamo che ci sia una colonna 'Date' e una colonna 'Close' con i prezzi di chiusura.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=10'>11</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=11'>12</a>\u001b[0m dati \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(csv_file)\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=12'>13</a>\u001b[0m dati[\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(dati[\u001b[39m'\u001b[39;49m\u001b[39mDate\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=13'>14</a>\u001b[0m dati[\u001b[39m'\u001b[39m\u001b[39mYear\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dati[\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39myear\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W4sdW50aXRsZWQ%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m dati\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "def carica_dati(csv_file):\n",
    "    \"\"\"\n",
    "    Carica i dati di serie storiche da un file CSV.\n",
    "    Supponiamo che ci sia una colonna 'Date' e una colonna 'Close' con i prezzi di chiusura.\n",
    "    \"\"\"\n",
    "    dati = pd.read_csv(csv_file)\n",
    "    dati['Date'] = pd.to_datetime(dati['Date'])\n",
    "    dati['Year'] = dati['Date'].dt.year\n",
    "    return dati\n",
    "\n",
    "def genera_rumore_bianco(seg_data, snr_db=20):\n",
    "    \"\"\"\n",
    "    Aggiunge rumore bianco gaussiano ai dati di chiusura con un rapporto segnale-rumore specificato.\n",
    "    \"\"\"\n",
    "    potenza_segnale = np.mean(seg_data**2)\n",
    "    potenza_rumore = potenza_segnale / (10**(snr_db / 10))\n",
    "    rumore_bianco = np.sqrt(potenza_rumore) * np.random.randn(len(seg_data))\n",
    "    dati_con_rumore = seg_data + rumore_bianco\n",
    "    return dati_con_rumore\n",
    "\n",
    "def genera_spettrogrammi_per_anno(dati, anno, num_spettrogrammi, output_dir, snr_db=20):\n",
    "    \"\"\"\n",
    "    Genera 200 spettrogrammi per un dato anno e li salva nella cartella di output.\n",
    "    \"\"\"\n",
    "    # Filtra i dati per l'anno specificato\n",
    "    dati_anno = dati[dati['Year'] == anno]['Close'].values\n",
    "    \n",
    "    # Dividi i dati in segmenti per generare più spettrogrammi\n",
    "    segment_length = len(dati_anno) // num_spettrogrammi\n",
    "    \n",
    "    for i in range(num_spettrogrammi):\n",
    "        start_idx = i * segment_length\n",
    "        end_idx = start_idx + segment_length\n",
    "        \n",
    "        # Seleziona i dati del segmento\n",
    "        seg_data = dati_anno[start_idx:end_idx]\n",
    "        \n",
    "        # Aggiungi rumore bianco\n",
    "        seg_data_rumore = genera_rumore_bianco(seg_data, snr_db)\n",
    "        \n",
    "        # Genera lo spettrogramma\n",
    "        f, t, Sxx = signal.spectrogram(seg_data_rumore, nperseg=128)\n",
    "        \n",
    "        # Plot dello spettrogramma\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        plt.pcolormesh(t, f, 10 * np.log10(Sxx))\n",
    "        plt.ylabel('Frequency [Hz]')\n",
    "        plt.xlabel('Time [sec]')\n",
    "        plt.title(f'Spettrogramma - Anno {anno} - {i+1}')\n",
    "        \n",
    "        # Salva lo spettrogramma\n",
    "        file_name = f'spettrogramma_anno_{anno}_{i+1}.png'\n",
    "        output_path = os.path.join(output_dir, file_name)\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "def genera_spettrogrammi_per_tutti_gli_anni(csv_file, output_dir, num_spettrogrammi_per_anno=200, snr_db=20):\n",
    "    \"\"\"\n",
    "    Genera spettrogrammi per ogni anno nel file CSV e li salva nella cartella di output.\n",
    "    \"\"\"\n",
    "    # Carica i dati dal file CSV\n",
    "    dati = carica_dati(csv_file)\n",
    "    \n",
    "    # Crea la cartella di output se non esiste\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Trova gli anni unici\n",
    "    anni = dati['Year'].unique()\n",
    "    \n",
    "    # Genera gli spettrogrammi per ogni anno\n",
    "    for anno in anni:\n",
    "        genera_spettrogrammi_per_anno(dati, anno, num_spettrogrammi_per_anno, output_dir, snr_db)\n",
    "\n",
    "# Esempio di utilizzo\n",
    "csv_file = '/Users/roberto/Desktop/UNI 3^ ANNO/tesi/dataset/adbe.csv'  # Percorso del file CSV con i dati\n",
    "output_dir = '/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectograms_adbe'  # Cartella di output per salvare gli spettrogrammi\n",
    "genera_spettrogrammi_per_tutti_gli_anni(csv_file, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jp/fnr369_172b9ghtllhyqdmtw0000gp/T/ipykernel_82985/4046725092.py:70: UserWarning: nperseg = 128 is greater than input length  = 1, using nperseg = 1\n",
      "  f, t, Sxx = signal.spectrogram(seg_data_rumore, nperseg=128)\n",
      "/var/folders/jp/fnr369_172b9ghtllhyqdmtw0000gp/T/ipykernel_82985/4046725092.py:74: RuntimeWarning: divide by zero encountered in log10\n",
      "  plt.pcolormesh(t, f, 10 * np.log10(Sxx), shading='gouraud')\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x111e87b90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/roberto/Library/Python/3.12/lib/python/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "# Funzione per caricare i dati\n",
    "def carica_dati(csv_file):\n",
    "    \"\"\"\n",
    "    Carica i dati dal file CSV e li prepara per la generazione dello spettrogramma.\n",
    "    \"\"\"\n",
    "    dati = pd.read_csv(csv_file)\n",
    "    return dati\n",
    "\n",
    "# Funzione per aggiungere rumore bianco gaussiano\n",
    "def genera_rumore_bianco(seg_data, snr_db=10):\n",
    "    \"\"\"\n",
    "    Aggiunge rumore bianco gaussiano ai dati di chiusura con un rapporto segnale-rumore specificato.\n",
    "    \"\"\"\n",
    "    potenza_segnale = np.mean(seg_data**2)\n",
    "    potenza_rumore = potenza_segnale / (10**(snr_db / 10))\n",
    "    rumore_bianco = np.sqrt(potenza_rumore) * np.random.randn(len(seg_data))\n",
    "    dati_con_rumore = seg_data + rumore_bianco\n",
    "    return dati_con_rumore\n",
    "\n",
    "# Funzione per stretching temporale\n",
    "def time_stretch(seg_data, stretch_factor=1.5):\n",
    "    \"\"\"\n",
    "    Applica stretching temporale ai dati senza cambiare la frequenza.\n",
    "    \"\"\"\n",
    "    return signal.resample(seg_data, int(len(seg_data) * stretch_factor))\n",
    "\n",
    "# Funzione per pitch shifting\n",
    "def pitch_shift(seg_data, shift_factor=1.2):\n",
    "    \"\"\"\n",
    "    Modifica la frequenza dei dati spostando il pitch.\n",
    "    \"\"\"\n",
    "    return seg_data * shift_factor\n",
    "\n",
    "# Funzione per generare spettrogrammi con data augmentation\n",
    "def genera_spettrogrammi_con_augmentation(dati, anno, num_spettrogrammi, output_dir, snr_db=10):\n",
    "    \"\"\"\n",
    "    Genera spettrogrammi per un dato anno con l'aggiunta di rumore bianco e data augmentation.\n",
    "    \"\"\"\n",
    "    # Filtra i dati per l'anno specificato\n",
    "    dati_anno = dati[dati['Year'] == anno].iloc[:, 1:].values.flatten()  # Prendi tutte le colonne Day_x\n",
    "    \n",
    "    # Dividi i dati in segmenti per generare più spettrogrammi\n",
    "    segment_length = len(dati_anno) // num_spettrogrammi\n",
    "    \n",
    "    for i in range(num_spettrogrammi):\n",
    "        start_idx = i * segment_length\n",
    "        end_idx = start_idx + segment_length\n",
    "        \n",
    "        # Seleziona i dati del segmento\n",
    "        seg_data = dati_anno[start_idx:end_idx]\n",
    "        \n",
    "        # Aggiungi rumore bianco\n",
    "        seg_data_rumore = genera_rumore_bianco(seg_data, snr_db)\n",
    "        \n",
    "        # Applica data augmentation alternata per creare varietà\n",
    "        if i % 3 == 0:\n",
    "            seg_data_rumore = time_stretch(seg_data_rumore, stretch_factor=np.random.uniform(0.8, 1.5))\n",
    "        elif i % 3 == 1:\n",
    "            seg_data_rumore = pitch_shift(seg_data_rumore, shift_factor=np.random.uniform(0.8, 1.2))\n",
    "        else:\n",
    "            seg_data_rumore = genera_rumore_bianco(seg_data_rumore, snr_db=15)  # Aggiungi ulteriore rumore\n",
    "\n",
    "        # Genera lo spettrogramma\n",
    "        f, t, Sxx = signal.spectrogram(seg_data_rumore, nperseg=128)\n",
    "        \n",
    "        # Plot dello spettrogramma\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        plt.pcolormesh(t, f, 10 * np.log10(Sxx), shading='gouraud')\n",
    "        plt.ylabel('Frequency [Hz]')\n",
    "        plt.xlabel('Time [sec]')\n",
    "        plt.title(f'Spettrogramma - Anno {anno} - {i+1}')\n",
    "        \n",
    "        # Salva lo spettrogramma\n",
    "        file_name = f'spettrogramma_anno_{anno}_{i+1}.png'\n",
    "        output_path = os.path.join(output_dir, file_name)\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "# Funzione per generare 2000 spettrogrammi in totale\n",
    "def genera_2000_spettrogrammi(csv_file, output_dir, num_spettrogrammi_totali=2000, snr_db=10):\n",
    "    \"\"\"\n",
    "    Genera spettrogrammi per tutti gli anni nel file CSV, applicando data augmentation.\n",
    "    \"\"\"\n",
    "    # Carica i dati dal file CSV\n",
    "    dati = carica_dati(csv_file)\n",
    "    \n",
    "    # Crea la cartella di output se non esiste\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Trova gli anni unici\n",
    "    anni = dati['Year'].unique()\n",
    "    num_anni = len(anni)\n",
    "    \n",
    "    # Calcola quanti spettrogrammi generare per ciascun anno\n",
    "    num_spettrogrammi_per_anno = num_spettrogrammi_totali // num_anni\n",
    "    \n",
    "    # Genera gli spettrogrammi per ogni anno\n",
    "    for anno in anni:\n",
    "        genera_spettrogrammi_con_augmentation(dati, anno, num_spettrogrammi_per_anno, output_dir, snr_db)\n",
    "\n",
    "# Esempio di utilizzo\n",
    "csv_file = '/Users/roberto/Desktop/UNI 3^ ANNO/tesi/dataset/adbe.csv'  # Percorso del file CSV con i dati\n",
    "output_dir = '/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi_adbe'  # Cartella di output per salvare gli spettrogrammi\n",
    "genera_2000_spettrogrammi(csv_file, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def carica_dati(csv_file):\n",
    "    \"\"\"\n",
    "    Carica i dati delle serie storiche dal file CSV.\n",
    "    \"\"\"\n",
    "    dati = pd.read_csv(csv_file)\n",
    "    return dati\n",
    "\n",
    "def genera_rumore_bianco(dati, snr_db=20):\n",
    "    \"\"\"\n",
    "    Aggiunge rumore bianco gaussiano ai dati delle serie storiche.\n",
    "    \"\"\"\n",
    "    potenza_segnale = np.mean(dati**2)\n",
    "    potenza_rumore = potenza_segnale / (10**(snr_db / 10))\n",
    "    rumore_bianco = np.sqrt(potenza_rumore) * np.random.randn(len(dati))\n",
    "    dati_con_rumore = dati + rumore_bianco\n",
    "    return dati_con_rumore\n",
    "\n",
    "def applica_filtro_gaussiano(dati, sigma=1):\n",
    "    \"\"\"\n",
    "    Applica un filtro gaussiano ai dati per creare variazioni.\n",
    "    \"\"\"\n",
    "    return gaussian_filter(dati, sigma=sigma)\n",
    "\n",
    "def time_stretch(seg_data, stretch_factor=1.5):\n",
    "    \"\"\"\n",
    "    Applica stretching temporale ai dati senza cambiare la frequenza.\n",
    "    \"\"\"\n",
    "    return signal.resample(seg_data, int(len(seg_data) * stretch_factor))\n",
    "\n",
    "def pitch_shift(seg_data, shift_factor=1.2):\n",
    "    \"\"\"\n",
    "    Modifica la frequenza dei dati spostando il pitch.\n",
    "    \"\"\"\n",
    "    return seg_data * shift_factor\n",
    "\n",
    "def genera_spettrogramma(dati, anno, output_dir, indice, snr_db=20, apply_filter=False, stretching=False, pitch=False):\n",
    "    \"\"\"\n",
    "    Genera lo spettrogramma per un determinato anno con vari data augmentation.\n",
    "    \"\"\"\n",
    "    # Aggiungi rumore bianco\n",
    "    dati_rumore = genera_rumore_bianco(dati, snr_db)\n",
    "    \n",
    "    # Applica filtri gaussiani\n",
    "    if apply_filter:\n",
    "        dati_rumore = applica_filtro_gaussiano(dati_rumore, sigma=np.random.uniform(0.5, 2.0))\n",
    "    \n",
    "    # Applica stretching temporale\n",
    "    if stretching:\n",
    "        dati_rumore = time_stretch(dati_rumore, stretch_factor=np.random.uniform(0.8, 1.5))\n",
    "    \n",
    "    # Applica pitch shifting\n",
    "    if pitch:\n",
    "        dati_rumore = pitch_shift(dati_rumore, shift_factor=np.random.uniform(0.8, 1.2))\n",
    "\n",
    "    # Genera lo spettrogramma\n",
    "    f, t, Sxx = signal.spectrogram(dati_rumore, nperseg=128)\n",
    "    \n",
    "    # Crea la figura del grafico\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.pcolormesh(t, f, 10 * np.log10(Sxx), shading='gouraud')\n",
    "    plt.colorbar(label='dB')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.title(f'Spettrogramma - Anno {anno} - Variante {indice}')\n",
    "\n",
    "    # Salva lo spettrogramma\n",
    "    output_file = os.path.join(output_dir, f'spettrogramma_anno_{anno}_variante_{indice}.png')\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "def genera_spettrogrammi_per_anni(csv_file, output_dir, snr_db=20, num_spettrogrammi_totali=2000):\n",
    "    \"\"\"\n",
    "    Genera 2000 spettrogrammi in totale per tutti gli anni del dataset e li salva nella cartella di output.\n",
    "    \"\"\"\n",
    "    # Carica i dati dal CSV\n",
    "    dati = carica_dati(csv_file)\n",
    "    \n",
    "    # Verifica se la cartella di output esiste, altrimenti la crea\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Trova gli anni unici\n",
    "    anni = dati['Year'].unique()\n",
    "    num_anni = len(anni)\n",
    "    \n",
    "    # Calcola quanti spettrogrammi per anno\n",
    "    num_spettrogrammi_per_anno = num_spettrogrammi_totali // num_anni\n",
    "    \n",
    "    # Cicla su ciascun anno e genera i vari spettrogrammi con data augmentation\n",
    "    for anno in anni:\n",
    "        dati_anno = dati[dati['Year'] == anno].iloc[:, 1:].values.flatten()\n",
    "        \n",
    "        for i in range(num_spettrogrammi_per_anno):\n",
    "            # Applica variazioni con diversi tipi di augmentation\n",
    "            if i % 3 == 0:\n",
    "                genera_spettrogramma(dati_anno, anno, output_dir, i+1, snr_db=snr_db, apply_filter=True)\n",
    "            elif i % 3 == 1:\n",
    "                genera_spettrogramma(dati_anno, anno, output_dir, i+1, snr_db=snr_db, stretching=True)\n",
    "            else:\n",
    "                genera_spettrogramma(dati_anno, anno, output_dir, i+1, snr_db=snr_db, pitch=True)\n",
    "\n",
    "# Esempio di utilizzo\n",
    "csv_file = '/Users/roberto/Desktop/UNI 3^ ANNO/tesi/dataset/adbe.csv'  # Percorso del file CSV\n",
    "output_dir = '/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi_adbe'  # Cartella di output\n",
    "genera_spettrogrammi_per_anni(csv_file, output_dir, num_spettrogrammi_totali=2000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def carica_dati(csv_file):\n",
    "    \"\"\"\n",
    "    Carica i dati delle serie storiche dal file CSV.\n",
    "    \"\"\"\n",
    "    dati = pd.read_csv(csv_file)\n",
    "    return dati\n",
    "\n",
    "def genera_rumore_bianco(dati, snr_db=20):\n",
    "    \"\"\"\n",
    "    Aggiunge rumore bianco gaussiano ai dati delle serie storiche.\n",
    "    \"\"\"\n",
    "    potenza_segnale = np.mean(dati**2)\n",
    "    potenza_rumore = potenza_segnale / (10**(snr_db / 10))\n",
    "    rumore_bianco = np.sqrt(potenza_rumore) * np.random.randn(len(dati))\n",
    "    dati_con_rumore = dati + rumore_bianco\n",
    "    return dati_con_rumore\n",
    "\n",
    "def applica_filtro_gaussiano(dati, sigma=1):\n",
    "    \"\"\"\n",
    "    Applica un filtro gaussiano ai dati per creare variazioni.\n",
    "    \"\"\"\n",
    "    return gaussian_filter(dati, sigma=sigma)\n",
    "\n",
    "def time_stretch(seg_data, stretch_factor=1.5):\n",
    "    \"\"\"\n",
    "    Applica stretching temporale ai dati senza cambiare la frequenza.\n",
    "    \"\"\"\n",
    "    return signal.resample(seg_data, int(len(seg_data) * stretch_factor))\n",
    "\n",
    "def pitch_shift(seg_data, shift_factor=1.2):\n",
    "    \"\"\"\n",
    "    Modifica la frequenza dei dati spostando il pitch.\n",
    "    \"\"\"\n",
    "    return seg_data * shift_factor\n",
    "\n",
    "def genera_spettrogramma(dati, anno, output_dir, indice, snr_db=20, apply_filter=False, stretching=False, pitch=False):\n",
    "    \"\"\"\n",
    "    Genera lo spettrogramma per un determinato anno con vari data augmentation.\n",
    "    \"\"\"\n",
    "    # Aggiungi rumore bianco\n",
    "    dati_rumore = genera_rumore_bianco(dati, snr_db)\n",
    "    \n",
    "    # Applica filtri gaussiani\n",
    "    if apply_filter:\n",
    "        dati_rumore = applica_filtro_gaussiano(dati_rumore, sigma=np.random.uniform(0.5, 2.0))\n",
    "    \n",
    "    # Applica stretching temporale\n",
    "    if stretching:\n",
    "        dati_rumore = time_stretch(dati_rumore, stretch_factor=np.random.uniform(0.8, 1.5))\n",
    "    \n",
    "    # Applica pitch shifting\n",
    "    if pitch:\n",
    "        dati_rumore = pitch_shift(dati_rumore, shift_factor=np.random.uniform(0.8, 1.2))\n",
    "\n",
    "    # Genera lo spettrogramma\n",
    "    f, t, Sxx = signal.spectrogram(dati_rumore, nperseg=128)\n",
    "    \n",
    "    # Crea la figura del grafico\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.pcolormesh(t, f, 10 * np.log10(Sxx), shading='gouraud')\n",
    "    plt.colorbar(label='dB')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.title(f'Spettrogramma - Anno {anno} - Variante {indice}')\n",
    "\n",
    "    # Salva lo spettrogramma\n",
    "    output_file = os.path.join(output_dir, f'spettrogramma_anno_{anno}_variante_{indice}.png')\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "def genera_spettrogrammi_per_anni(csv_file, output_dir, snr_db=20, num_spettrogrammi_totali=2000):\n",
    "    \"\"\"\n",
    "    Genera 2000 spettrogrammi in totale per tutti gli anni del dataset e li salva nella cartella di output.\n",
    "    \"\"\"\n",
    "    # Carica i dati dal CSV\n",
    "    dati = carica_dati(csv_file)\n",
    "    \n",
    "    # Verifica se la cartella di output esiste, altrimenti la crea\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Trova gli anni unici\n",
    "    anni = dati['Year'].unique()\n",
    "    num_anni = len(anni)\n",
    "    \n",
    "    # Calcola quanti spettrogrammi per anno\n",
    "    num_spettrogrammi_per_anno = num_spettrogrammi_totali // num_anni\n",
    "    \n",
    "    # Cicla su ciascun anno e genera i vari spettrogrammi con data augmentation\n",
    "    for anno in anni:\n",
    "        dati_anno = dati[dati['Year'] == anno].iloc[:, 1:].values.flatten()\n",
    "        \n",
    "        for i in range(num_spettrogrammi_per_anno):\n",
    "            # Applica variazioni con diversi tipi di augmentation\n",
    "            if i % 3 == 0:\n",
    "                genera_spettrogramma(dati_anno, anno, output_dir, i+1, snr_db=snr_db, apply_filter=True)\n",
    "            elif i % 3 == 1:\n",
    "                genera_spettrogramma(dati_anno, anno, output_dir, i+1, snr_db=snr_db, stretching=True)\n",
    "            else:\n",
    "                genera_spettrogramma(dati_anno, anno, output_dir, i+1, snr_db=snr_db, pitch=True)\n",
    "\n",
    "# Esempio di utilizzo\n",
    "csv_file = '/Users/roberto/Desktop/UNI 3^ ANNO/tesi/dataset/jnj.csv'  # Percorso del file CSV\n",
    "output_dir = '/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi_jnj'  # Cartella di output\n",
    "genera_spettrogrammi_per_anni(csv_file, output_dir, num_spettrogrammi_totali=2000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rimuovi contorni\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rimosso: spettrogramma_anno_2022_variante_74.png (Varianza: 924.76599, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_158.png (Varianza: 928.45090, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_29.png (Varianza: 921.48151, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_146.png (Varianza: 929.83420, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_197.png (Varianza: 934.39589, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_2.png (Varianza: 927.41201, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_8.png (Varianza: 931.79172, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_194.png (Varianza: 931.03664, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_26.png (Varianza: 928.58128, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_137.png (Varianza: 938.73176, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_146.png (Varianza: 928.97765, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_80.png (Varianza: 935.82731, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_59.png (Varianza: 930.74640, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_95.png (Varianza: 935.24956, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_140.png (Varianza: 936.83913, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_122.png (Varianza: 929.18578, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_113.png (Varianza: 947.13599, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_44.png (Varianza: 960.56617, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_11.png (Varianza: 925.22037, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_89.png (Varianza: 973.59686, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_182.png (Varianza: 934.74768, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_185.png (Varianza: 929.33185, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_98.png (Varianza: 935.37179, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_41.png (Varianza: 926.13780, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_176.png (Varianza: 939.38486, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_80.png (Varianza: 924.37025, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_65.png (Varianza: 926.26530, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_71.png (Varianza: 930.08305, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_92.png (Varianza: 931.95921, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_200.png (Varianza: 935.52439, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_86.png (Varianza: 931.09565, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_161.png (Varianza: 928.60288, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_62.png (Varianza: 928.21481, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_50.png (Varianza: 932.91378, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_155.png (Varianza: 931.16707, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_191.png (Varianza: 933.16250, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_113.png (Varianza: 930.28438, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_44.png (Varianza: 925.53472, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_83.png (Varianza: 929.35468, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_89.png (Varianza: 927.19930, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_131.png (Varianza: 930.78285, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_119.png (Varianza: 928.68125, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_92.png (Varianza: 936.94013, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_86.png (Varianza: 937.16347, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_197.png (Varianza: 929.57036, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_122.png (Varianza: 929.41933, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_125.png (Varianza: 933.08490, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_110.png (Varianza: 927.17619, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_20.png (Varianza: 934.64928, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_173.png (Varianza: 928.27242, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_56.png (Varianza: 926.74647, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_182.png (Varianza: 930.43918, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_11.png (Varianza: 925.33260, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_62.png (Varianza: 933.23297, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_170.png (Varianza: 965.26183, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_29.png (Varianza: 930.11633, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_119.png (Varianza: 934.59733, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_122.png (Varianza: 943.86722, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_59.png (Varianza: 933.39508, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_53.png (Varianza: 930.70752, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_149.png (Varianza: 936.17693, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_20.png (Varianza: 923.18126, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_146.png (Varianza: 941.13953, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_152.png (Varianza: 932.47552, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_14.png (Varianza: 934.69512, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_134.png (Varianza: 931.54539, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_98.png (Varianza: 928.03053, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_44.png (Varianza: 923.77377, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_68.png (Varianza: 929.75104, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_50.png (Varianza: 929.22043, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_125.png (Varianza: 924.31200, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_128.png (Varianza: 932.86514, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_38.png (Varianza: 923.61648, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_26.png (Varianza: 935.49967, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_32.png (Varianza: 963.05513, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_65.png (Varianza: 928.79416, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_110.png (Varianza: 928.48359, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_179.png (Varianza: 937.65768, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_68.png (Varianza: 939.71792, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_170.png (Varianza: 940.77990, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_95.png (Varianza: 932.45619, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_29.png (Varianza: 932.04357, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_68.png (Varianza: 928.11997, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_107.png (Varianza: 936.48714, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_113.png (Varianza: 927.57967, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_83.png (Varianza: 921.35299, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_5.png (Varianza: 922.35951, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_71.png (Varianza: 938.99022, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_2.png (Varianza: 926.45617, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_158.png (Varianza: 933.67827, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_20.png (Varianza: 934.96070, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_53.png (Varianza: 931.37632, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_98.png (Varianza: 930.47589, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_110.png (Varianza: 931.00205, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_107.png (Varianza: 929.39604, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_35.png (Varianza: 931.44614, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_122.png (Varianza: 928.62756, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_89.png (Varianza: 931.95854, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_44.png (Varianza: 933.22190, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_167.png (Varianza: 927.16109, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_35.png (Varianza: 929.53972, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_2.png (Varianza: 918.82541, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_53.png (Varianza: 942.81813, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_32.png (Varianza: 927.75045, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_161.png (Varianza: 935.42048, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_14.png (Varianza: 967.29405, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_152.png (Varianza: 931.91741, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_98.png (Varianza: 924.73980, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_38.png (Varianza: 930.78246, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_170.png (Varianza: 927.50873, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_53.png (Varianza: 927.34301, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_149.png (Varianza: 928.38340, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_74.png (Varianza: 936.99697, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_68.png (Varianza: 926.37791, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_107.png (Varianza: 937.52806, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_23.png (Varianza: 941.41488, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_11.png (Varianza: 922.86328, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_125.png (Varianza: 923.20162, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_179.png (Varianza: 935.18094, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_56.png (Varianza: 937.92028, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_173.png (Varianza: 926.68722, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_29.png (Varianza: 937.82004, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_185.png (Varianza: 929.36397, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_44.png (Varianza: 935.53715, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_164.png (Varianza: 941.36017, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_86.png (Varianza: 931.76972, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_125.png (Varianza: 923.99038, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_161.png (Varianza: 941.77727, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_53.png (Varianza: 929.23961, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_104.png (Varianza: 938.78102, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_176.png (Varianza: 934.17140, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_143.png (Varianza: 927.30090, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_14.png (Varianza: 927.57773, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_194.png (Varianza: 966.35213, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_188.png (Varianza: 938.22252, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_101.png (Varianza: 941.11628, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_143.png (Varianza: 934.75650, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_194.png (Varianza: 935.51731, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_149.png (Varianza: 937.28022, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_50.png (Varianza: 925.89273, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_17.png (Varianza: 933.79619, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_122.png (Varianza: 940.58387, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_80.png (Varianza: 925.98719, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_170.png (Varianza: 927.76534, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_188.png (Varianza: 930.74037, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_182.png (Varianza: 928.19879, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_65.png (Varianza: 919.76519, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_2.png (Varianza: 928.48742, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_92.png (Varianza: 931.65148, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_26.png (Varianza: 943.92657, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_116.png (Varianza: 941.50234, Pixel bianchi: 0.96)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def rimuovi_immagini_vuote(cartella, soglia_varianza=0.01, soglia_bianco=0.95):\n",
    "    \"\"\"\n",
    "    Rimuove tutte le immagini bianche o vuote dalla cartella specificata.\n",
    "    \n",
    "    Argomenti:\n",
    "    - cartella: percorso della cartella dove si trovano le immagini.\n",
    "    - soglia_varianza: se la varianza dell'immagine è inferiore a questa soglia, l'immagine viene considerata vuota.\n",
    "    - soglia_bianco: percentuale di pixel bianchi oltre la quale l'immagine viene considerata vuota.\n",
    "    \"\"\"\n",
    "    # Ottieni la lista di file nella cartella\n",
    "    files = os.listdir(cartella)\n",
    "    \n",
    "    # Filtra solo i file immagine (png, jpg, jpeg)\n",
    "    immagini = [f for f in files if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for immagine in immagini:\n",
    "        percorso_immagine = os.path.join(cartella, immagine)\n",
    "        \n",
    "        # Carica l'immagine\n",
    "        try:\n",
    "            with Image.open(percorso_immagine) as img:\n",
    "                # Converti l'immagine in scala di grigi\n",
    "                img_gray = img.convert('L')\n",
    "                \n",
    "                # Converti l'immagine in array numpy\n",
    "                img_array = np.array(img_gray)\n",
    "                \n",
    "                # Calcola la varianza dell'immagine\n",
    "                varianza = np.var(img_array)\n",
    "                \n",
    "                # Calcola la percentuale di pixel bianchi (consideriamo \"bianchi\" i pixel con valore > 245)\n",
    "                pixel_bianchi = np.sum(img_array > 245)\n",
    "                percentuale_pixel_bianchi = pixel_bianchi / img_array.size\n",
    "                \n",
    "                # Se la varianza è inferiore alla soglia o l'immagine ha troppi pixel bianchi, elimina l'immagine\n",
    "                if varianza < soglia_varianza or percentuale_pixel_bianchi >= soglia_bianco:\n",
    "                    os.remove(percorso_immagine)\n",
    "                    print(f\"Rimosso: {immagine} (Varianza: {varianza:.5f}, Pixel bianchi: {percentuale_pixel_bianchi:.2f})\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Errore nell'elaborazione dell'immagine {immagine}: {e}\")\n",
    "\n",
    "# Esempio di utilizzo\n",
    "cartella = '/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi_adbe'  # Sostituisci con il percorso della tua cartella\n",
    "rimuovi_immagini_vuote(cartella)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rimosso: spettrogramma_anno_2019_variante_134.png (Varianza: 932.52911, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_74.png (Varianza: 924.76599, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_170.png (Varianza: 922.38959, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_68.png (Varianza: 933.27338, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_152.png (Varianza: 934.75070, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_197.png (Varianza: 927.30433, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_14.png (Varianza: 932.26910, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_2.png (Varianza: 924.18726, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_8.png (Varianza: 929.77360, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_110.png (Varianza: 929.35082, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_158.png (Varianza: 941.60311, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_8.png (Varianza: 927.87708, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_164.png (Varianza: 936.62389, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_137.png (Varianza: 928.40626, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_167.png (Varianza: 934.53867, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_173.png (Varianza: 930.05360, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_20.png (Varianza: 937.41291, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_143.png (Varianza: 931.13680, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_194.png (Varianza: 935.52513, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_56.png (Varianza: 927.20605, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_104.png (Varianza: 938.56154, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_131.png (Varianza: 937.05249, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_29.png (Varianza: 935.26643, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_125.png (Varianza: 941.09373, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_44.png (Varianza: 923.58263, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_68.png (Varianza: 969.38748, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_200.png (Varianza: 932.37531, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_35.png (Varianza: 930.75335, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_155.png (Varianza: 921.50657, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_152.png (Varianza: 938.37444, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_20.png (Varianza: 931.27139, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_176.png (Varianza: 929.04960, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_119.png (Varianza: 940.10868, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_122.png (Varianza: 929.30655, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_140.png (Varianza: 921.38815, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_92.png (Varianza: 934.95192, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_26.png (Varianza: 937.95182, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_86.png (Varianza: 939.57943, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_77.png (Varianza: 931.10984, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_146.png (Varianza: 942.51367, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_185.png (Varianza: 934.01995, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_182.png (Varianza: 931.76901, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_74.png (Varianza: 931.08244, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_137.png (Varianza: 927.65236, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_95.png (Varianza: 919.93244, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_113.png (Varianza: 927.28078, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_107.png (Varianza: 934.02691, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_83.png (Varianza: 923.79929, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_23.png (Varianza: 933.87462, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_11.png (Varianza: 928.68919, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_77.png (Varianza: 924.53677, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_164.png (Varianza: 936.09827, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_53.png (Varianza: 930.45248, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_47.png (Varianza: 918.96014, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_173.png (Varianza: 932.39500, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_26.png (Varianza: 955.52472, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_113.png (Varianza: 927.24652, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_125.png (Varianza: 933.07514, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_104.png (Varianza: 928.91940, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_80.png (Varianza: 938.59075, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_167.png (Varianza: 934.85522, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_191.png (Varianza: 938.29102, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_8.png (Varianza: 931.02086, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_62.png (Varianza: 926.14089, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_155.png (Varianza: 932.84046, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_164.png (Varianza: 941.44816, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_158.png (Varianza: 932.91906, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_116.png (Varianza: 935.58396, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_179.png (Varianza: 929.50223, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_11.png (Varianza: 924.16087, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_80.png (Varianza: 929.25968, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_53.png (Varianza: 928.46862, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_38.png (Varianza: 925.11799, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_101.png (Varianza: 934.22290, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_188.png (Varianza: 928.33183, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_152.png (Varianza: 939.80723, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_83.png (Varianza: 928.49492, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_125.png (Varianza: 934.97110, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_122.png (Varianza: 927.51204, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_98.png (Varianza: 932.91143, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_38.png (Varianza: 920.62181, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_113.png (Varianza: 933.22306, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_128.png (Varianza: 938.90662, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_200.png (Varianza: 941.16519, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_104.png (Varianza: 929.20816, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_80.png (Varianza: 927.67114, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_179.png (Varianza: 934.65530, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_188.png (Varianza: 926.22520, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_23.png (Varianza: 930.98224, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_68.png (Varianza: 928.23066, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_152.png (Varianza: 929.40623, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_56.png (Varianza: 932.67793, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_104.png (Varianza: 928.73289, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_62.png (Varianza: 941.91271, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_41.png (Varianza: 926.21389, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_14.png (Varianza: 931.18528, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_152.png (Varianza: 934.64605, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_80.png (Varianza: 936.02660, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_173.png (Varianza: 931.47517, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_182.png (Varianza: 930.36312, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_20.png (Varianza: 934.96070, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_53.png (Varianza: 937.61222, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_170.png (Varianza: 932.18583, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_77.png (Varianza: 935.42067, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_86.png (Varianza: 928.19087, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_116.png (Varianza: 931.98828, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_194.png (Varianza: 935.96648, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_8.png (Varianza: 928.46681, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_17.png (Varianza: 921.54197, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_89.png (Varianza: 929.70917, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_74.png (Varianza: 934.63882, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_155.png (Varianza: 945.32183, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_128.png (Varianza: 939.86239, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_107.png (Varianza: 934.00487, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_53.png (Varianza: 926.02356, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_140.png (Varianza: 930.12722, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_197.png (Varianza: 937.72580, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_104.png (Varianza: 933.63249, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_143.png (Varianza: 929.49259, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_194.png (Varianza: 930.06455, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_98.png (Varianza: 921.72509, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_191.png (Varianza: 929.37822, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_158.png (Varianza: 932.00498, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_92.png (Varianza: 938.51634, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_173.png (Varianza: 927.32867, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_176.png (Varianza: 935.09245, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_11.png (Varianza: 923.72805, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_125.png (Varianza: 928.73714, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_35.png (Varianza: 941.65722, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_5.png (Varianza: 921.68150, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_164.png (Varianza: 936.11052, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_158.png (Varianza: 935.98458, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_176.png (Varianza: 931.25741, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_8.png (Varianza: 927.62981, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_2.png (Varianza: 921.49562, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_161.png (Varianza: 940.61565, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_47.png (Varianza: 932.25425, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_80.png (Varianza: 926.73091, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2016_variante_20.png (Varianza: 936.92968, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_122.png (Varianza: 925.88479, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2014_variante_197.png (Varianza: 932.01556, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_53.png (Varianza: 931.36591, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_47.png (Varianza: 933.07886, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2021_variante_194.png (Varianza: 932.32355, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_32.png (Varianza: 925.70524, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_2.png (Varianza: 922.12738, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_149.png (Varianza: 928.85831, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2017_variante_200.png (Varianza: 937.41179, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_170.png (Varianza: 923.99785, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_56.png (Varianza: 927.52764, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_62.png (Varianza: 923.58368, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2015_variante_89.png (Varianza: 927.97772, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2019_variante_104.png (Varianza: 936.64293, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2022_variante_44.png (Varianza: 929.02363, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2018_variante_5.png (Varianza: 928.89766, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2013_variante_17.png (Varianza: 926.47226, Pixel bianchi: 0.96)\n",
      "Rimosso: spettrogramma_anno_2020_variante_59.png (Varianza: 927.06897, Pixel bianchi: 0.96)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def rimuovi_immagini_vuote(cartella, soglia_varianza=0.01, soglia_bianco=0.95):\n",
    "    \"\"\"\n",
    "    Rimuove tutte le immagini bianche o vuote dalla cartella specificata.\n",
    "    \n",
    "    Argomenti:\n",
    "    - cartella: percorso della cartella dove si trovano le immagini.\n",
    "    - soglia_varianza: se la varianza dell'immagine è inferiore a questa soglia, l'immagine viene considerata vuota.\n",
    "    - soglia_bianco: percentuale di pixel bianchi oltre la quale l'immagine viene considerata vuota.\n",
    "    \"\"\"\n",
    "    # Ottieni la lista di file nella cartella\n",
    "    files = os.listdir(cartella)\n",
    "    \n",
    "    # Filtra solo i file immagine (png, jpg, jpeg)\n",
    "    immagini = [f for f in files if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for immagine in immagini:\n",
    "        percorso_immagine = os.path.join(cartella, immagine)\n",
    "        \n",
    "        # Carica l'immagine\n",
    "        try:\n",
    "            with Image.open(percorso_immagine) as img:\n",
    "                # Converti l'immagine in scala di grigi\n",
    "                img_gray = img.convert('L')\n",
    "                \n",
    "                # Converti l'immagine in array numpy\n",
    "                img_array = np.array(img_gray)\n",
    "                \n",
    "                # Calcola la varianza dell'immagine\n",
    "                varianza = np.var(img_array)\n",
    "                \n",
    "                # Calcola la percentuale di pixel bianchi (consideriamo \"bianchi\" i pixel con valore > 245)\n",
    "                pixel_bianchi = np.sum(img_array > 245)\n",
    "                percentuale_pixel_bianchi = pixel_bianchi / img_array.size\n",
    "                \n",
    "                # Se la varianza è inferiore alla soglia o l'immagine ha troppi pixel bianchi, elimina l'immagine\n",
    "                if varianza < soglia_varianza or percentuale_pixel_bianchi >= soglia_bianco:\n",
    "                    os.remove(percorso_immagine)\n",
    "                    print(f\"Rimosso: {immagine} (Varianza: {varianza:.5f}, Pixel bianchi: {percentuale_pixel_bianchi:.2f})\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Errore nell'elaborazione dell'immagine {immagine}: {e}\")\n",
    "\n",
    "# Esempio di utilizzo\n",
    "cartella = '/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi_jnj'  # Sostituisci con il percorso della tua cartella\n",
    "rimuovi_immagini_vuote(cartella)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing e creazione classe dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def carica_spettrogrammi(cartella_tsla, cartella_kk):\n",
    "    \"\"\"\n",
    "    Carica gli spettrogrammi per adbe e jnj, etichettandoli correttamente.\n",
    "    \n",
    "    - cartella_tsla: percorso della cartella con gli spettrogrammi di adbe.\n",
    "    - cartella_kk: percorso della cartella con gli spettrogrammi di jnj.\n",
    "    \"\"\"\n",
    "    spettrogrammi = []\n",
    "    labels = []\n",
    "    \n",
    "    # Carica spettrogrammi TSLA\n",
    "    for file in os.listdir(cartella_tsla):\n",
    "        if file.endswith('.png'):\n",
    "            img = Image.open(os.path.join(cartella_tsla, file)).convert('RGB')\n",
    "            img_resized = img.resize((128, 128))  # Ridimensiona tutte le immagini\n",
    "            spettrogrammi.append(np.array(img_resized))\n",
    "            labels.append(0)  # Etichetta TSLA come 0\n",
    "\n",
    "    # Carica spettrogrammi KK\n",
    "    for file in os.listdir(cartella_kk):\n",
    "        if file.endswith('.png'):\n",
    "            img = Image.open(os.path.join(cartella_kk, file)).convert('RGB')\n",
    "            img_resized = img.resize((128, 128))  # Ridimensiona tutte le immagini\n",
    "            spettrogrammi.append(np.array(img_resized))\n",
    "            labels.append(1)  # Etichetta KK come 1\n",
    "\n",
    "    # Converti a numpy array e normalizza\n",
    "    spettrogrammi = np.array(spettrogrammi) / 255.0\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return spettrogrammi, labels\n",
    "\n",
    "# Carica gli spettrogrammi\n",
    "spettrogrammi, labels = carica_spettrogrammi('/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spettrogrammi/spectrogrammi_adbe', '/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spettrogrammi/spectrogrammi_jnj')\n",
    "\n",
    "# Suddividi i dati in train (70%), validation (20%) e test (10%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(spettrogrammi, labels, test_size=0.30, stratify=labels, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.33, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Converti le etichette in formato categorico\n",
    "y_train_cat = to_categorical(y_train, num_classes=2)\n",
    "y_val_cat = to_categorical(y_val, num_classes=2)\n",
    "y_test_cat = to_categorical(y_test, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57600</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,372,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57600\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m7,372,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,392,578</span> (28.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,392,578\u001b[0m (28.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,392,578</span> (28.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,392,578\u001b[0m (28.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def crea_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  # Due classi: TSLA, KK\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Creazione del modello CNN\n",
    "model = crea_cnn()\n",
    "\n",
    "# Mostra il riassunto del modello\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correzione del percorso per il checkpoint del modello\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Definisci callback per l'early stopping e per salvare il miglior modello\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "#checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# Addestramento del modello\n",
    "#history = model.fit(X_train, y_train_cat, \n",
    "                    #validation_data=(X_val, y_val_cat),\n",
    "                    #epochs=50, \n",
    "                    #batch_size=32, \n",
    "                    #callbacks=[early_stop, checkpoint],\n",
    "                    #verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.4877 - loss: 0.6932\n",
      "Epoch 1: val_loss improved from inf to 0.69313, saving model to /Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi/output/final_model.keras\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - accuracy: 0.4879 - loss: 0.6932 - val_accuracy: 0.5027 - val_loss: 0.6931\n",
      "Epoch 2/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.4913 - loss: 0.6932\n",
      "Epoch 2: val_loss did not improve from 0.69313\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.4913 - loss: 0.6932 - val_accuracy: 0.5027 - val_loss: 0.6931\n",
      "Epoch 3/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.5132 - loss: 0.6931\n",
      "Epoch 3: val_loss did not improve from 0.69313\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.5131 - loss: 0.6931 - val_accuracy: 0.5027 - val_loss: 0.6931\n",
      "Epoch 4/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.4879 - loss: 0.6934\n",
      "Epoch 4: val_loss did not improve from 0.69313\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - accuracy: 0.4879 - loss: 0.6934 - val_accuracy: 0.5027 - val_loss: 0.6931\n",
      "Epoch 5/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.4752 - loss: 0.6933\n",
      "Epoch 5: val_loss did not improve from 0.69313\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.4752 - loss: 0.6933 - val_accuracy: 0.5027 - val_loss: 0.6931\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Definisci un percorso dove hai i permessi di scrittura, ad esempio una cartella sul desktop\n",
    "checkpoint = ModelCheckpoint('/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi/output/final_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# Addestramento del modello\n",
    "history = model.fit(X_train, y_train_cat, \n",
    "                    validation_data=(X_val, y_val_cat),\n",
    "                    epochs=50, \n",
    "                    batch_size=32, \n",
    "                    callbacks=[early_stop, checkpoint],\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4945 - loss: 0.6932\n",
      "Accuracy sul test set: 50.14%\n"
     ]
    }
   ],
   "source": [
    "# Valutazione sul test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=1)\n",
    "print(f'Accuracy sul test set: {test_acc * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stai utilizzando il dispositivo: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Verifica se MPS (Metal) o CUDA è disponibile\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Stai utilizzando il dispositivo: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpettrogrammaDataset(Dataset):\n",
    "    def __init__(self, root_dir, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Directory principale contenente le cartelle con le immagini degli spettrogrammi.\n",
    "            labels (dict): Dizionario che associa il nome della cartella alla sua etichetta.\n",
    "            transform (callable, optional): Trasformazioni da applicare alle immagini.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.img_labels = []\n",
    "\n",
    "        for label_name, label in labels.items():\n",
    "            label_dir = os.path.join(root_dir, label_name)\n",
    "            for img_file in os.listdir(label_dir):\n",
    "                if img_file.endswith('.png'):\n",
    "                    self.images.append(os.path.join(label_dir, img_file))\n",
    "                    self.img_labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.img_labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 128)  # Layer fully connected\n",
    "        self.fc2 = nn.Linear(128, 2)  # Due classi\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 16 * 16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorso delle cartelle con gli spettrogrammi\n",
    "root_dir = '/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spettrogrammi'\n",
    "labels = {'spectrogrammi_adbe': 0, 'spectrogrammi_jnj': 1}  # Cambia class1 e class2 con i nomi delle tue cartelle\n",
    "\n",
    "# Trasformazioni e creazione dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Creazione del dataset\n",
    "dataset = SpettrogrammaDataset(root_dir=root_dir, labels=labels, transform=transform)\n",
    "\n",
    "# Suddivisione in train, validation, test (70:20:10)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Creazione dei DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, epochs=20, lr=0.001, model_path='best_model.pth'):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    best_val_loss = float('inf')  # Inizializza la migliore loss\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        total = 0\n",
    "        \n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_acc += torch.sum(preds == labels.data).float()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_loss = running_loss / total\n",
    "        train_acc = running_acc / total\n",
    "        \n",
    "        # Valutazione\n",
    "        val_loss, val_acc = validate_model(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Salva il modello se la validazione è migliorata\n",
    "        if val_loss < best_val_loss:\n",
    "            print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving model...\")\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "def validate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_acc += torch.sum(preds == labels.data).float()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    val_loss = val_loss / total\n",
    "    val_acc = val_acc / total\n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    # Matrice di confusione\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Report di classificazione\n",
    "    report = classification_report(all_labels, all_preds)\n",
    "    print(report)\n",
    "\n",
    "    # Visualizzazione della matrice di confusione\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from inf to 0.6928. Saving model...\n",
      "Epoch 1/50, Train Loss: 0.6990, Train Acc: 0.4809, Val Loss: 0.6928, Val Acc: 0.5284\n",
      "Epoch 2/50, Train Loss: 0.6937, Train Acc: 0.5010, Val Loss: 0.6952, Val Acc: 0.4716\n",
      "Epoch 3/50, Train Loss: 0.6948, Train Acc: 0.5041, Val Loss: 0.6934, Val Acc: 0.4716\n",
      "Epoch 4/50, Train Loss: 0.6931, Train Acc: 0.5133, Val Loss: 0.6930, Val Acc: 0.5284\n",
      "Epoch 5/50, Train Loss: 0.6940, Train Acc: 0.5172, Val Loss: 0.6934, Val Acc: 0.4716\n",
      "Epoch 6/50, Train Loss: 0.6932, Train Acc: 0.5125, Val Loss: 0.6946, Val Acc: 0.4716\n",
      "Epoch 7/50, Train Loss: 0.6929, Train Acc: 0.5137, Val Loss: 0.6946, Val Acc: 0.4716\n",
      "Epoch 8/50, Train Loss: 0.6929, Train Acc: 0.5137, Val Loss: 0.6949, Val Acc: 0.4716\n",
      "Epoch 9/50, Train Loss: 0.6930, Train Acc: 0.5137, Val Loss: 0.6948, Val Acc: 0.4716\n",
      "Epoch 10/50, Train Loss: 0.6929, Train Acc: 0.5137, Val Loss: 0.6950, Val Acc: 0.4716\n",
      "Epoch 11/50, Train Loss: 0.6929, Train Acc: 0.5137, Val Loss: 0.6950, Val Acc: 0.4716\n",
      "Epoch 12/50, Train Loss: 0.6928, Train Acc: 0.5137, Val Loss: 0.6947, Val Acc: 0.4716\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cella 25\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m CNN()\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m \u001b[39m# Avvio dell'addestramento\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=4'>5</a>\u001b[0m train_model(model, train_loader, val_loader, device, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m, model_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi/output/best_model.pth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=6'>7</a>\u001b[0m \u001b[39m# Carica il miglior modello salvato\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39m/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi/output/best_model.pth\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;32mUntitled-1.ipynb Cella 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=9'>10</a>\u001b[0m running_acc \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=10'>11</a>\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;49;00m imgs, labels \u001b[39min\u001b[39;49;00m train_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=13'>14</a>\u001b[0m     imgs, labels \u001b[39m=\u001b[39;49m imgs\u001b[39m.\u001b[39;49mto(device), labels\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=15'>16</a>\u001b[0m     \u001b[39m# Forward pass\u001b[39;49;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39m\"\u001b[39m\u001b[39m__getitems__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/dataset.py:419\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices]\n",
      "\u001b[1;32mUntitled-1.ipynb Cella 25\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=25'>26</a>\u001b[0m     img_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages[idx]\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=26'>27</a>\u001b[0m     image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(img_path)\u001b[39m.\u001b[39;49mconvert(\u001b[39m'\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=27'>28</a>\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_labels[idx]\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y126sdW50aXRsZWQ%3D?line=29'>30</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/PIL/Image.py:1069\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m   1066\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt allocate palette entry for transparency\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1067\u001b[0m     \u001b[39mreturn\u001b[39;00m new_im\n\u001b[0;32m-> 1069\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mLAB\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode, mode):\n\u001b[1;32m   1070\u001b[0m     other_mode \u001b[39m=\u001b[39m mode \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLAB\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[1;32m   1071\u001b[0m     \u001b[39mif\u001b[39;00m other_mode \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mRGBA\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mRGBX\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/PIL/Image.py:523\u001b[0m, in \u001b[0;36mImage.mode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msize\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]:\n\u001b[1;32m    521\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_size\n\u001b[0;32m--> 523\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    524\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmode\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    525\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode\n\u001b[1;32m    527\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_new\u001b[39m(\u001b[39mself\u001b[39m, im) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Image:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Inizializzazione del modello\n",
    "model = CNN()\n",
    "\n",
    "# Avvio dell'addestramento\n",
    "train_model(model, train_loader, val_loader, device, epochs=50, lr=0.001, model_path='/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi/output/best_model.pth')\n",
    "\n",
    "# Carica il miglior modello salvato\n",
    "model.load_state_dict(torch.load('/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi/output/best_model.pth'))\n",
    "\n",
    "# Testa il modello sui dati di test\n",
    "test_model(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stai utilizzando il dispositivo: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Verifica se MPS (Metal) o CUDA è disponibile\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Stai utilizzando il dispositivo: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpettrogrammaDataset(Dataset):\n",
    "    def __init__(self, root_dir, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Directory principale contenente le cartelle con le immagini degli spettrogrammi.\n",
    "            labels (dict): Dizionario che associa il nome della cartella alla sua etichetta.\n",
    "            transform (callable, optional): Trasformazioni da applicare alle immagini.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.img_labels = []\n",
    "\n",
    "        for label_name, label in labels.items():\n",
    "            label_dir = os.path.join(root_dir, label_name)\n",
    "            for img_file in os.listdir(label_dir):\n",
    "                if img_file.endswith('.png'):\n",
    "                    self.images.append(os.path.join(label_dir, img_file))\n",
    "                    self.img_labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.img_labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 128)  # Flatten layer per immagini 128x128\n",
    "        self.fc2 = nn.Linear(128, 2)  # Due classi: JNJ e ADBE\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 16 * 16)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorso delle cartelle con gli spettrogrammi\n",
    "root_dir = '/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spettrogrammi'  # Inserisci il percorso corretto\n",
    "labels = {'spectrogrammi_jnj': 0, 'spectrogrammi_adbe': 1}  # Etichette delle cartelle\n",
    "\n",
    "# Trasformazioni per le immagini (es. ridimensionamento e conversione in tensori)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Creazione del dataset\n",
    "dataset = SpettrogrammaDataset(root_dir=root_dir, labels=labels, transform=transform)\n",
    "\n",
    "# Suddivisione in train (70%), validation (20%), test (10%)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Creazione dei DataLoader per batch di immagini\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, epochs=20, lr=0.001, model_path='best_model.pth'):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    best_val_loss = float('inf')  # Inizializza la migliore loss\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        total = 0\n",
    "        \n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_acc += torch.sum(preds == labels.data).float()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_loss = running_loss / total\n",
    "        train_acc = running_acc / total\n",
    "        \n",
    "        # Valutazione sul validation set\n",
    "        val_loss, val_acc = validate_model(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Salva il modello se la validazione è migliorata\n",
    "        if val_loss < best_val_loss:\n",
    "            print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving model...\")\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_acc += torch.sum(preds == labels.data).float()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    val_loss = val_loss / total\n",
    "    val_acc = val_acc / total\n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    # Matrice di confusione\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Report di classificazione\n",
    "    report = classification_report(all_labels, all_preds, target_names=['JNJ', 'ADBE'])\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Visualizzazione della matrice di confusione\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['JNJ', 'ADBE'], yticklabels=['JNJ', 'ADBE'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from inf to 0.6936. Saving model...\n",
      "Epoch 1/20, Train Loss: 0.6953, Train Acc: 0.5017, Val Loss: 0.6936, Val Acc: 0.4892\n",
      "Epoch 2/20, Train Loss: 0.6935, Train Acc: 0.5083, Val Loss: 0.6936, Val Acc: 0.4892\n",
      "Epoch 3/20, Train Loss: 0.6931, Train Acc: 0.5075, Val Loss: 0.6936, Val Acc: 0.4892\n",
      "Epoch 4/20, Train Loss: 0.6931, Train Acc: 0.5075, Val Loss: 0.6936, Val Acc: 0.4892\n",
      "Epoch 5/20, Train Loss: 0.6932, Train Acc: 0.5075, Val Loss: 0.6936, Val Acc: 0.4892\n",
      "Validation loss improved from 0.6936 to 0.6934. Saving model...\n",
      "Epoch 6/20, Train Loss: 0.6932, Train Acc: 0.5010, Val Loss: 0.6934, Val Acc: 0.4892\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cella 33\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m CNN()\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m \u001b[39m# Addestramento del modello con 50 epoche\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=4'>5</a>\u001b[0m train_model(model, train_loader, val_loader, device, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m, model_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi/output/best_model.pth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=6'>7</a>\u001b[0m \u001b[39m# Caricamento del miglior modello salvato\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39m/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi/output/best_model.pth\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;32mUntitled-1.ipynb Cella 33\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=9'>10</a>\u001b[0m running_acc \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=10'>11</a>\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;49;00m imgs, labels \u001b[39min\u001b[39;49;00m train_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=13'>14</a>\u001b[0m     imgs, labels \u001b[39m=\u001b[39;49m imgs\u001b[39m.\u001b[39;49mto(device), labels\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=15'>16</a>\u001b[0m     \u001b[39m# Forward pass\u001b[39;49;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39m\"\u001b[39m\u001b[39m__getitems__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/dataset.py:419\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices]\n",
      "\u001b[1;32mUntitled-1.ipynb Cella 33\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=25'>26</a>\u001b[0m     img_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages[idx]\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=26'>27</a>\u001b[0m     image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(img_path)\u001b[39m.\u001b[39;49mconvert(\u001b[39m'\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=27'>28</a>\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_labels[idx]\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y141sdW50aXRsZWQ%3D?line=29'>30</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/PIL/Image.py:941\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert\u001b[39m(\n\u001b[1;32m    890\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    891\u001b[0m     mode: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    895\u001b[0m     colors: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m256\u001b[39m,\n\u001b[1;32m    896\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Image:\n\u001b[1;32m    897\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \u001b[39m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[39m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[39m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 941\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    943\u001b[0m     has_transparency \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtransparency\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\n\u001b[1;32m    944\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mode \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    945\u001b[0m         \u001b[39m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/PIL/ImageFile.py:291\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(msg)\n\u001b[1;32m    290\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> 291\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    292\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    293\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Inizializzazione del modello\n",
    "model = CNN()\n",
    "\n",
    "# Addestramento del modello con 50 epoche\n",
    "train_model(model, train_loader, val_loader, device, epochs=20, lr=0.001, model_path='/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi/output/best_model.pth')\n",
    "\n",
    "# Caricamento del miglior modello salvato\n",
    "model.load_state_dict(torch.load('/Users/roberto/Desktop/UNI 3^ ANNO/tesi/spectrogrammi/output/best_model.pth'))\n",
    "\n",
    "# Test del modello sui dati di test\n",
    "test_model(model, test_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
